{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18d8c6e-cf39-4c5b-8e75-0fbeccce44f2",
   "metadata": {},
   "source": [
    "# Questionnaire Chapter 4: Training a Digit Classifier\n",
    "\n",
    "1. How is a grayscale image represented on a computer? How about a color image?\n",
    "\n",
    "> Images are represented by arrays with pixel values representing the content of the image. For greyscale images, a 2-dimensional array is used with the pixels representing the greyscale values, with a range of 256 integers. A value of 0 would represent white, and a value of 255 represents black, and different shades of greyscale in between. For color images, three color channels (red, green, blue) are typicall used, with a separate 256-range 2D array used for each channel. A pixel value of 0 again represents white, with 255 representing solid red, green, or blue. The three 2-D arrays form a final 3-D array (rank 3 tensor) representing the color image.\n",
    "\n",
    "2. How are the files and folders in the `MNIST_SAMPLE` dataset structured? Why?\n",
    "\n",
    "> The `MNIST` dataset follows a common layout for ML datasets: separate folders for the training set and the validation (and/or test) set. Every practicioner could generate their own train/validation-split of the data. Public datasets are usually pre-split to simplifiy comparing results between implementations/publications.\n",
    ">\n",
    "> fastai `MNIST_SAMPLE` has two subfolders two subsubfolders 3 and 7 which contain the .jpg files for the respective class of images. This is a common way of organizing datasets comprised of pictures. For the full `MNIST` dataset there are 10 subsubfolders, one for the images for each digit.\n",
    "\n",
    "3. Explain how the \"pixel similarity\" approach to classifying digits works.\n",
    "\n",
    "> The main idea is to find the average pixel value for every pixel of the 3s, then do the same for the 7s. This will give two group averages, defining what we might call the \"ideal\" 3 and 7. Then, to classify an image as one digit or the other, we see which of these two ideal digits the image is most similar to.\n",
    "\n",
    "4. What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n",
    "\n",
    "> Solution at the end of the notebook.\n",
    "\n",
    "5. What is a \"rank-3 tensor\"?\n",
    "\n",
    "> It's a tensor with 3 dimensions. The rank of a tensor is the number of dimensions it has. In particular, the rank of a tensor is independent of its shape or dimensionality, e.g., a tensor of shape 2x2x2 and a tensor of shape 3x5x7 both have rank 3. Note that the term “rank” has different meanings in the context of tensors and matrices (where it refers to the number of linearly independent column vectors).\n",
    "\n",
    "6. What is the difference between tensor rank and shape? How do you get the rank from the shape?\n",
    "\n",
    "> __*Rank*__ is the number of axes or dimensions in a tensor; __*shape*__ is the size of each axis of a tensor.\n",
    "\n",
    "7. What are RMSE and L1 norm?\n",
    "\n",
    "> Root mean squared error (RMSE) is also called the L2 norm, and mean absolute difference (MAE), also called the L1 norm, are two commonly used methods of measuring “distance”. Simple differences do not work because some difference are positive and others are negative, canceling each other out. Therefore, a function that focuses on the magnitudes of the differences is needed to properly measure distances. The simplest would be to add the absolute values of the differences, which is what MAE is. RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring).\n",
    "\n",
    "8. How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?\n",
    "\n",
    "> As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster, as they use underlying C code which is much faster than pure Python. Even better, PyTorch allows you to run operations on GPU, which will have significant speedup if there are parallel operations that can be done.\n",
    "\n",
    "9. Create a 3×3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "\n",
    "> Solution at the end of the notebook.\n",
    "\n",
    "10. What is broadcasting?\n",
    "\n",
    "> Scientific/numerical Python packages like NumPy and PyTorch will often implement broadcasting that often makes code easier to write. In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor. In this way, operations can be performed between tensors with different rank.\n",
    "\n",
    "11. Are metrics generally calculated using the training set, or the validation set? Why?\n",
    "\n",
    "> We use the __*validation set*__ to calculate metrics because we don't want the model to overfit - that is, train a model to work well only on our training data.\n",
    "\n",
    "12. What is SGD?\n",
    "\n",
    "> Stochastic Gradient Descent (SGD) is an optimization algorithm that updates the parameters of a model to minimize a given loss function that was evaluated on the predictions and target. The main idea behind SGD is that the gradient of the loss function determines the best way to update the parameters to minimize the loss function.\n",
    "\n",
    "13. Why does SGD use mini-batches?\n",
    "\n",
    "> \n",
    "\n",
    "14. What are the seven steps in SGD for machine learning?\n",
    "15. How do we initialize the weights in a model?\n",
    "16. What is \"loss\"?\n",
    "17. Why can't we always use a high learning rate?\n",
    "18. What is a \"gradient\"?\n",
    "19. Do you need to know how to calculate gradients yourself?\n",
    "20. Why can't we use accuracy as a loss function?\n",
    "21. Draw the sigmoid function. What is special about its shape?\n",
    "22. What is the difference between a loss function and a metric?\n",
    "23. What is the function to calculate new weights using a learning rate?\n",
    "24. What does the `DataLoader` class do?\n",
    "25. Write pseudocode showing the basic steps taken in each epoch for SGD.\n",
    "26. Create a function that, if passed two arguments `[1,2,3,4]` and `'abcd'`, returns `[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]`. What is special about that output data structure?\n",
    "27. What does `view` do in PyTorch?\n",
    "28. What are the \"bias\" parameters in a neural network? Why do we need them?\n",
    "29. What does the `@` operator do in Python?\n",
    "30. What does the `backward` method do?\n",
    "31. Why do we have to zero the gradients?\n",
    "32. What information do we have to pass to `Learner`?\n",
    "33. Show Python or pseudocode for the basic steps of a training loop.\n",
    "34. What is \"ReLU\"? Draw a plot of it for values from `-2` to `+2`.\n",
    "35. What is an \"activation function\"?\n",
    "36. What's the difference between `F.relu` and `nn.ReLU`?\n",
    "37. The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60883344-48d1-4c2b-8007-fc271325938f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Create a list comprehension that selects odd numbers from a list and doubles them.\n",
    "# List of numbers\n",
    "nums = range(10)\n",
    "\n",
    "# Double odd numbers\n",
    "double_odd = [2*n for n in nums if n % 2 != 0]\n",
    "double_odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411103fb-1f8f-42fe-94a2-65cbe905e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]] \n",
      "\n",
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [14 16 18]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10, 12],\n",
       "       [16, 18]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Create a 3×3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "import numpy as np\n",
    "\n",
    "array = np.array(range(1, 10)).reshape(3, 3)\n",
    "print(array, '\\n')\n",
    "\n",
    "array = array*2\n",
    "print(array, '\\n')\n",
    "\n",
    "array[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e39219-c95e-4c80-be91-80bb47a7b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]]) \n",
      "\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [14., 16., 18.]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10., 12.],\n",
       "        [16., 18.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.Tensor(range(1, 10)).view(3,3)\n",
    "print(tensor, '\\n')\n",
    "\n",
    "tensor = 2*tensor\n",
    "print(tensor, '\\n')\n",
    "\n",
    "tensor[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37834f1f-1c97-46f9-96dd-410d382437dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 26. Create a function...\n",
    "def f(nums, letters):\n",
    "    return [(nums[i], letters[i]) for i in range(len(nums))]\n",
    "\n",
    "nums = range(1, 5)\n",
    "letters = 'abcd'\n",
    "f(nums, letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a31763-5d04-46c0-923d-2e385b28703d",
   "metadata": {},
   "source": [
    "### Deep learning terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e48be-8a5e-42ec-854d-74010aec4fae",
   "metadata": {},
   "source": [
    "| Term | Meaning |\n",
    "| ---- | ------- |\n",
    "|ReLU | Function that returns 0 for negative numbers and doesn't change positive numbers. |\n",
    "|Mini-batch | A small group of inputs and labels gathered together in two arrays. A gradient descent step is updated on this batch (rather than a whole epoch). |\n",
    "|Forward pass | Applying the model to some input and computing the predictions. |\n",
    "|Loss | A value that represents how well (or badly) our model is doing. |\n",
    "|Gradient | The derivative of the loss with respect to some parameter of the model. |\n",
    "|Backward pass | Computing the gradients of the loss with respect to all model parameters. |\n",
    "|Gradient descent | Taking a step in the directions opposite to the gradients to make the model parameters a little bit better. |\n",
    "|Learning rate | The size of the step we take when applying SGD to update the parameters of the model. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d5b25-58bb-45ee-8516-b8b4ff00085e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
